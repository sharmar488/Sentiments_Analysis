{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "adb86401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45fe5fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sentiment                                             review\n",
      "0              1  This book is such a life saver.  It has been s...\n",
      "1              1  I bought this a few times for my older son and...\n",
      "2              1  This is great for basics, but I wish the space...\n",
      "3              1  This book is perfect!  I'm a first time new mo...\n",
      "4              1  During your postpartum stay at the hospital th...\n",
      "...          ...                                                ...\n",
      "18501         -1  I really liked this monitor at first, but the ...\n",
      "18502         -1  Apparently you get what you pay for.  I've use...\n",
      "18503         -1  The old saying holds true with this product --...\n",
      "18504         -1  We did a great deal of research before purchas...\n",
      "18505         -1  I ordered these after having great success wit...\n",
      "\n",
      "[18506 rows x 2 columns]\n",
      "                                              review_new\n",
      "0      Perfect for new parents. We were able to keep ...\n",
      "1      Helps me know exactly how my babies day has go...\n",
      "2      I wanted an alternative to printing out daily ...\n",
      "3      My 3 month old son spend half of his days with...\n",
      "4      The Baby Tracker brand books are the absolute ...\n",
      "...                                                  ...\n",
      "18501  WTF. The pieces don't fit together, the instru...\n",
      "18502  I've gone through a couple of video baby monit...\n",
      "18503  This monitor is cheap and doesn't work well. O...\n",
      "18504  These monitors do not work at all, I even atte...\n",
      "18505  Short story, I was very disappointed with the ...\n",
      "\n",
      "[18506 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#reading both file using two functions read_table and read_csv\n",
    "train_data = pd.read_table(\"train_file.dat\",header=None,names=[\"sentiment\",\"review\"])\n",
    "test_data = pd.read_csv(\"test1.csv\",sep='\\n', header=None,names=[\"review_new\"])\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f37883d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this book is such a life saver  it has been so helpful to be able to go back to track trends answer pediatrician questions or communicate with each other when you are up at different times of the night with a newborn  i think it is one of those things that everyone should be required to have before they leave the hospital  we went through all the pages of the newborn version then moved to the infant version and will finish up the second infant book third total right as our baby turns   see other things that are must haves for baby at \n",
      "\n",
      "perfect for new parents we were able to keep track of babys feeding sleep and diaper change schedule for the first two and a half months of her life made life easier when the doctor would ask questions about habits because we had it all right there\n"
     ]
    }
   ],
   "source": [
    "#using regex on both trainig and test data to remove numeric as well as any special character after converting it to lowercase\n",
    "train_data.review=train_data.review.str.lower()\n",
    "test_data.review_new=test_data.review_new.str.lower()\n",
    "train_data['review'] = [re.sub(\"[^a-z ]\",\"\", str(x)) for x in train_data['review']]\n",
    "test_data['review_new'] = [re.sub(\"[^a-z ]\",\"\", str(x)) for x in test_data['review_new']]\n",
    "print(train_data.review[0])\n",
    "print()\n",
    "print(test_data.review_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3856186d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'life', 'saver', 'help', 'abl', 'go', 'back', 'track', 'trend', 'answer', 'pediatrician', 'question', 'communic', 'differ', 'time', 'night', 'newborn', 'think', 'one', 'thing', 'everyon', 'requir', 'leav', 'hospit', 'went', 'page', 'newborn', 'version', 'move', 'infant', 'version', 'finish', 'second', 'infant', 'book', 'third', 'total', 'right', 'babi', 'turn', 'see', 'thing', 'must', 'have', 'babi']\n"
     ]
    }
   ],
   "source": [
    "#performing stemming and removing stopwords from training data\n",
    "stemmer=SnowballStemmer(\"english\")\n",
    "stopWords = set(stopwords.words('english'))\n",
    "train_data['review'] = train_data['review'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split() if word not in (stopWords)]))\n",
    "train_data['review'] = [word_tokenize(str(x)) for x in train_data['review']]\n",
    "print(train_data['review'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4bf727ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['perfect', 'new', 'parent', 'abl', 'keep', 'track', 'babi', 'feed', 'sleep', 'diaper', 'chang', 'schedul', 'first', 'two', 'half', 'month', 'life', 'made', 'life', 'easier', 'doctor', 'would', 'ask', 'question', 'habit', 'right']\n"
     ]
    }
   ],
   "source": [
    "#performing stemming and removing stopwords from test data\n",
    "test_data['review_new'] = test_data['review_new'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split() if word not in (stopWords)]))\n",
    "test_data['review_new'] = [word_tokenize(str(x)) for x in test_data['review_new']]\n",
    "print(test_data['review_new'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15560e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18506, 27864)\n"
     ]
    }
   ],
   "source": [
    "#Using TF-idf vectorizer on training data\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_data['review']=[\" \".join(review) for review in train_data['review'].values]\n",
    "x_train=vectorizer.fit_transform(train_data['review'])\n",
    "print(x_train.shape)\n",
    "X=x_train.toarray()\n",
    "Y=train_data['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8cb2a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18506, 27864)\n"
     ]
    }
   ],
   "source": [
    "#Using transform method on test data on the basis of given vocabulary from training data\n",
    "test_data['review_new']=[\" \".join(review) for review in test_data['review_new'].values]\n",
    "x_test=vectorizer.transform(test_data['review_new'])\n",
    "x_test=x_test.toarray()\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "31355a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=20000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training model on train data\n",
    "log_reg = LogisticRegression(max_iter=20000)\n",
    "log_reg.fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09c34798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting labels on test data\n",
    "prediction = log_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c76eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing labels in text file name output\n",
    "with open(\"output.txt\", \"w\") as out_file:\n",
    "    for element in prediction:\n",
    "        print(element,file=out_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
